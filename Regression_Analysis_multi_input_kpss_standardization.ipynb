{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1fcd5be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from joblib import Parallel, delayed\n",
    "from itertools import combinations\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import re\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "p_val_thres = 0.1\n",
    "correl_thres = 0.05\n",
    "spss_thres = 0.01\n",
    "#add adf test threshold\n",
    "adf_thres = 0.1\n",
    "vif_thres = 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee697d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MULTIPLE FACTOR FILTERING\n",
    "def fit_and_check(var_tuple, X, Y):\n",
    "    X_feature = sm.add_constant(X[list(var_tuple)])\n",
    "    model = sm.OLS(Y, X_feature).fit()\n",
    "\n",
    "    if all(model.pvalues[1:] <= p_val_thres) and all([variance_inflation_factor(X_feature.values, i) <= vif_thres for i in range(X_feature.shape[1])]) and all(model.params[1:] >= 0):\n",
    "        return model\n",
    "    else:\n",
    "        return model\n",
    "        #return None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ef09daa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_main(raw_data):\n",
    "    \n",
    "    start_row = raw_data.iloc[:, 1].first_valid_index()\n",
    "\n",
    "    X = raw_data.iloc[3:,2:].reset_index(drop=True)\n",
    "    X = X.astype('float64')\n",
    "\n",
    "    Y = raw_data.iloc[start_row:,1].reset_index(drop=True)\n",
    "    Y = Y.astype('float64')\n",
    "\n",
    "    diff_treatment = raw_data.iloc[1,2:]\n",
    "    sign_treatment = raw_data.iloc[2,2:]\n",
    "    group_treatment = raw_data.iloc[0,2:]\n",
    "\n",
    "    for i in range(len(X.columns)):\n",
    "        if sign_treatment[i] == '-1' or sign_treatment[i] == -1:\n",
    "            X.iloc[:,i] = X.iloc[:,i] * -1 / 100\n",
    "        else:\n",
    "            X.iloc[:,i] = X.iloc[:,i] / 100\n",
    "\n",
    "    for i in range(len(X.columns)):\n",
    "        X.rename(columns={X.columns[i]: X.columns[i]+'_'+group_treatment[i]},inplace=True)\n",
    "        \n",
    "    X_diff = X.copy()\n",
    "    X_diff.loc[:] = np.nan\n",
    "    for i in range(len(X.columns)):\n",
    "        if diff_treatment[i] == 'Y':\n",
    "            X_diff.iloc[:,i] = X.iloc[:,i].diff()\n",
    "\n",
    "    X_diff = X_diff.dropna(axis=1, how='all')\n",
    "    X_diff = X_diff.add_suffix('_diff')\n",
    "\n",
    "    X = pd.concat([X, X_diff], axis = 1)\n",
    "    X = X.iloc[start_row-3:,:].reset_index(drop=True)\n",
    "\n",
    "    # STANDARDIZATION & CAUCHY\n",
    "    X = (X - X.mean()) / X.std(ddof=1)\n",
    "    # X = 0.5+np.arctan(X)/np.pi\n",
    "    # X = (X - X.mean()) / X.std(ddof=1)\n",
    "\n",
    "\n",
    "    # SINGLE FACTOR FILTERING\n",
    "    roll_corr = X.copy()\n",
    "    roll_corr.loc[:] = np.nan\n",
    "\n",
    "    for i in range(2,len(roll_corr)+1):\n",
    "        for j in range(len(roll_corr.columns)):\n",
    "            roll_corr.iloc[i-1,j] = np.corrcoef(X.iloc[:i,j],Y[:i])[0,1]\n",
    "            \n",
    "    stationary_df = X.copy()\n",
    "    stationary_df.loc[:] = np.nan\n",
    "    stationary_df = stationary_df.head(1)\n",
    "\n",
    "    #adf test for stationary (previous is kpss)\n",
    "    for i in range(len(stationary_df.columns)):\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\", category=sm.tools.sm_exceptions.InterpolationWarning)\n",
    "            stationary_df.iloc[0,i] = sm.tsa.stattools.kpss(X.iloc[:,i], regression='ct')[1]\n",
    "\n",
    "    ### (new add)output stationary test result  ###\n",
    "    stationary_output = np.transpose(stationary_df)\n",
    "    stationary_output.columns = ['Test_Value']\n",
    "    stationary_output['Result'] = ['Pass' if val > spss_thres else 'Fail' for val in stationary_output['Test_Value']]\n",
    "\n",
    "    X = X.drop(columns=X.columns[((stationary_df < spss_thres).squeeze() | (roll_corr.iloc[-1] < correl_thres))])\n",
    "    \n",
    "    \n",
    "    # # RENAME COLUMNS\n",
    "    # new_column_names = []\n",
    "    # for col in X.columns:\n",
    "    #     # Check if the column name contains \"_diff\"\n",
    "    #     if \"_diff\" in col:\n",
    "    #         # Use regular expressions to extract the relevant parts\n",
    "    #         match = re.search(r'(.{3})_diff', col)\n",
    "    #         if match:\n",
    "    #             # Extract the three characters before \"_diff\"\n",
    "    #             prefix = match.group(1)\n",
    "    #             # Update the column name as per the rule\n",
    "    #             new_col = col.replace(f\"{prefix}_diff\", f\"diff_{prefix}\")\n",
    "    #             # Append the updated column name to the list\n",
    "    #             new_column_names.append(new_col)\n",
    "    #         else:\n",
    "    #             # Column name didn't match the expected pattern, keep the original name\n",
    "    #             new_column_names.append(col)\n",
    "    #     else:\n",
    "    #         # Column name doesn't contain \"_diff\", keep the original name\n",
    "    #         new_column_names.append(col)\n",
    "\n",
    "    # # Assign the new column names to the DataFrame\n",
    "    # X.columns = new_column_names\n",
    "\n",
    "    model_list = []\n",
    "\n",
    "    for n in range (2,5):\n",
    "        # Create a list of all possible N-factor variable combinations\n",
    "        print(f\"Testing N = {n} !\")\n",
    "        # Extract suffixes from column names\n",
    "\n",
    "        var_combinations = list(combinations(pd.Index([col for col in X.columns]), n))\n",
    "\n",
    "        # Filter out combinations with repeated suffixes\n",
    "        var_combinations_filtered = []\n",
    "        for comb in var_combinations:\n",
    "            # Extract the suffixes from the current combination\n",
    "            combination_suffixes = [col[-3:] for col in comb]\n",
    "\n",
    "            # Check if the combination has repeated suffixes\n",
    "            has_repeated_suffixes = False\n",
    "            for i in range(len(combination_suffixes)):\n",
    "                for j in range(i + 1, len(combination_suffixes)):\n",
    "                    if combination_suffixes[i] == combination_suffixes[j]:\n",
    "                        has_repeated_suffixes = True\n",
    "                        break\n",
    "                if has_repeated_suffixes:\n",
    "                    break\n",
    "\n",
    "            if has_repeated_suffixes:\n",
    "                continue\n",
    "\n",
    "            var_combinations_filtered.append(comb)\n",
    "\n",
    "        # Convert the filtered list of combinations to a list of tuples\n",
    "        var_combinations = [tuple(comb) for comb in var_combinations_filtered]\n",
    "\n",
    "        #var_combinations = list(combinations(pd.Index([col for col in X.columns]), n))\n",
    "        \n",
    "        with Parallel(n_jobs=-1) as parallel:\n",
    "            model_n_list = parallel(delayed(fit_and_check)(var_tuple, X, Y) for var_tuple in var_combinations)\n",
    "        \n",
    "        model_n_list = [model for model in model_n_list if model is not None]\n",
    "        model_list.extend(model_n_list)\n",
    "\n",
    "    final_result = pd.DataFrame(columns=['Factor_1', 'Factor_2', 'Factor_3', 'Factor_4', 'Adj. R-Squared',\n",
    "                            'Intercept', 'Coefficient_1', 'Coefficient_2', 'Coefficient_3', 'Coefficient_4',\n",
    "                            'P-Value_Intercept', 'P-Value_1', 'P-Value_2', 'P-Value_3', 'P-Value_4', 'VIF_1', 'VIF_2', 'VIF_3', 'VIF_4'])\n",
    "\n",
    "    # Create an empty list to store model_info dictionaries\n",
    "    model_info_list = []\n",
    "\n",
    "    # Iterate over the models in model_list\n",
    "    for i, model in enumerate(model_list):\n",
    "        # Extract the model information\n",
    "        factors = model.params.index[1:5]  # Assuming the factor names are stored as index values in the model parameters\n",
    "        adj_r_squared = model.rsquared_adj\n",
    "        intercept = model.params[0]\n",
    "        coefficients = model.params[1:5]\n",
    "        p_values = model.pvalues.values[:5]\n",
    "        vif_factors = [variance_inflation_factor(model.model.exog, j) for j in range(1, len(factors)+1)]\n",
    "        # Create a dictionary with the model information\n",
    "        model_info = {'Factor_1': factors[0] if len(factors) > 0 else '',\n",
    "                    'Factor_2': factors[1] if len(factors) > 1 else '',\n",
    "                    'Factor_3': factors[2] if len(factors) > 2 else '',\n",
    "                    'Factor_4': factors[3] if len(factors) > 3 else '',\n",
    "                    'Adj. R-Squared': adj_r_squared,\n",
    "                    'Intercept': intercept,\n",
    "                    'Coefficient_1': coefficients[0] if len(coefficients) > 0 else '',\n",
    "                    'Coefficient_2': coefficients[1] if len(coefficients) > 1 else '',\n",
    "                    'Coefficient_3': coefficients[2] if len(coefficients) > 2 else '',\n",
    "                    'Coefficient_4': coefficients[3] if len(coefficients) > 3 else '',\n",
    "                    'P-Value_Intercept': p_values[0] if len(p_values) > 0 else '',\n",
    "                    'P-Value_1': p_values[1] if len(p_values) > 1 else '',\n",
    "                    'P-Value_2': p_values[2] if len(p_values) > 2 else '',\n",
    "                    'P-Value_3': p_values[3] if len(p_values) > 3 else '',\n",
    "                    'P-Value_4': p_values[4] if len(p_values) > 4 else '',\n",
    "                    'VIF_1': vif_factors[0] if len(vif_factors) > 0 else '',\n",
    "                    'VIF_2': vif_factors[1] if len(vif_factors) > 1 else '',\n",
    "                    'VIF_3': vif_factors[2] if len(vif_factors) > 2 else '',\n",
    "                    'VIF_4': vif_factors[3] if len(vif_factors) > 3 else ''\n",
    "                    }\n",
    "\n",
    "        # Append the model information to the list\n",
    "        model_info_list.append(model_info)\n",
    "\n",
    "    # Concatenate the model_info dictionaries into a DataFrame\n",
    "    final_result = pd.concat([final_result, pd.DataFrame(model_info_list)])\n",
    "\n",
    "    \n",
    "    \n",
    "    ##### (new add) test checking (p_vale, coefficient, VIF)#####\n",
    "    final_result['num_factor'] = 4-final_result[['Coefficient_1', 'Coefficient_2', 'Coefficient_3', 'Coefficient_4']].apply(lambda row: row.str.count('').sum(),axis=1)\n",
    "    final_result['num_factor'] = final_result['num_factor'].apply(lambda x: int(x))\n",
    "\n",
    "    #p_value test\n",
    "    final_result['P-Value_1'] = final_result['P-Value_1'].replace('',999)\n",
    "    final_result['P-Value_2'] = final_result['P-Value_2'].replace('',999)\n",
    "    final_result['P-Value_3'] = final_result['P-Value_3'].replace('',999)\n",
    "    final_result['P-Value_4'] = final_result['P-Value_4'].replace('',999)\n",
    "\n",
    "    conditions_pvalue = [\n",
    "        (final_result['P-Value_1'] > p_val_thres) & (final_result['P-Value_1'] != 999),\n",
    "        (final_result['P-Value_2'] > p_val_thres) & (final_result['P-Value_2'] != 999),\n",
    "        (final_result['P-Value_3'] > p_val_thres) & (final_result['P-Value_3'] != 999),\n",
    "        (final_result['P-Value_4'] > p_val_thres) & (final_result['P-Value_4'] != 999),\n",
    "    ]\n",
    "\n",
    "    choices_pvalue = [\n",
    "        'Fail',\n",
    "        'Fail',\n",
    "        'Fail',\n",
    "        'Fail',\n",
    "    ]\n",
    "\n",
    "    final_result = (final_result.assign(\n",
    "        p_value_test = np.select(conditions_pvalue, choices_pvalue, default='Pass')))\n",
    "\n",
    "    final_result['P-Value_1'] = final_result['P-Value_1'].replace(999,'')\n",
    "    final_result['P-Value_2'] = final_result['P-Value_2'].replace(999,'')\n",
    "    final_result['P-Value_3'] = final_result['P-Value_3'].replace(999,'')\n",
    "    final_result['P-Value_4'] = final_result['P-Value_4'].replace(999,'')\n",
    "\n",
    "\n",
    "    #Coefficient test\n",
    "    final_result['Coefficient_1'] = final_result['Coefficient_1'].replace('',999)\n",
    "    final_result['Coefficient_2'] = final_result['Coefficient_2'].replace('',999)\n",
    "    final_result['Coefficient_3'] = final_result['Coefficient_3'].replace('',999)\n",
    "    final_result['Coefficient_4'] = final_result['Coefficient_4'].replace('',999)\n",
    "\n",
    "    conditions_coe = [\n",
    "        (final_result['Coefficient_1'] < 0) & (final_result['Coefficient_1'] != 999),\n",
    "        (final_result['Coefficient_2'] < 0) & (final_result['Coefficient_2'] != 999),\n",
    "        (final_result['Coefficient_3'] < 0) & (final_result['Coefficient_3'] != 999),\n",
    "        (final_result['Coefficient_4'] < 0) & (final_result['Coefficient_4'] != 999),   \n",
    "    ]\n",
    "\n",
    "    choices_coe = [\n",
    "        'Fail',\n",
    "        'Fail',\n",
    "        'Fail',\n",
    "        'Fail',\n",
    "    ]\n",
    "\n",
    "    final_result = (final_result.assign(\n",
    "        Coefficient_test = np.select(conditions_coe, choices_coe, default='Pass')))\n",
    "\n",
    "    final_result['Coefficient_1'] = final_result['Coefficient_1'].replace(999,'')\n",
    "    final_result['Coefficient_2'] = final_result['Coefficient_2'].replace(999,'')\n",
    "    final_result['Coefficient_3'] = final_result['Coefficient_3'].replace(999,'')\n",
    "    final_result['Coefficient_4'] = final_result['Coefficient_4'].replace(999,'')\n",
    "\n",
    "    #VIF Test\n",
    "    final_result['VIF_1'] = final_result['VIF_1'].replace('',999)\n",
    "    final_result['VIF_2'] = final_result['VIF_2'].replace('',999)\n",
    "    final_result['VIF_3'] = final_result['VIF_3'].replace('',999)\n",
    "    final_result['VIF_4'] = final_result['VIF_4'].replace('',999)\n",
    "    \n",
    "    conditions_vif = [\n",
    "        (final_result['VIF_1'] > vif_thres) & (final_result['VIF_1'] != 999),\n",
    "        (final_result['VIF_2'] > vif_thres) & (final_result['VIF_2'] != 999),\n",
    "        (final_result['VIF_3'] > vif_thres) & (final_result['VIF_3'] != 999),\n",
    "        (final_result['VIF_4'] > vif_thres) & (final_result['VIF_4'] != 999),\n",
    "    ]\n",
    "\n",
    "    choices_vif = [\n",
    "        'Fail',\n",
    "        'Fail',\n",
    "        'Fail',\n",
    "        'Fail',\n",
    "    ]\n",
    "\n",
    "    final_result = (final_result.assign(\n",
    "        VIF_test = np.select(conditions_vif, choices_vif, default='Pass')))\n",
    "\n",
    "    final_result['VIF_1'] = final_result['VIF_1'].replace(999,'')\n",
    "    final_result['VIF_2'] = final_result['VIF_2'].replace(999,'')\n",
    "    final_result['VIF_3'] = final_result['VIF_3'].replace(999,'')\n",
    "    final_result['VIF_4'] = final_result['VIF_4'].replace(999,'')\n",
    "\n",
    "    #final_result\n",
    "    final_result['test_final'] = final_result[['Coefficient_test','p_value_test','VIF_test']].apply(lambda row: 'Pass' if all(val == \"Pass\" for val in row) else 'Fail', axis=1)\n",
    "\n",
    "\n",
    "    # Sort the DataFrame by descending order of the adjusted R-squared values\n",
    "    final_result = final_result.sort_values(by='Adj. R-Squared', ascending=False).reset_index(drop=True)\n",
    "\n",
    "    #final_result.to_csv('Regression_Output.csv'), and statinoary_output\n",
    "    return (final_result, stationary_output, roll_corr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6e793643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processinginput_moodys.csv:\n",
      "Testing N = 2 !\n",
      "Testing N = 3 !\n",
      "Testing N = 4 !\n"
     ]
    }
   ],
   "source": [
    "# Get the list of CSV files in the 'input' subfolder\n",
    "input_folder = r'C:\\Users\\UV665AR\\OneDrive - EY\\8.Fusion\\MEF model\\run_input'\n",
    "csv_files = [file for file in os.listdir(input_folder) if file.endswith('.csv')]\n",
    "# Create a writer object to save results to Excel\n",
    "writer = pd.ExcelWriter(r'C:\\Users\\UV665AR\\OneDrive - EY\\8.Fusion\\MEF model\\run_output\\Regression_Output_moodys.xlsx')\n",
    "\n",
    "# Process each input file\n",
    "for csv_file in csv_files:\n",
    "    print('Processing'+csv_file+':')\n",
    "    result, stationary_output, roll_corr = my_main(pd.read_csv(os.path.join(input_folder, csv_file)))\n",
    "    ### (new add) input stationary test result to the excel ###\n",
    "    roll_corr.to_excel(writer, sheet_name='Rolling_Correlation',index=True)\n",
    "    stationary_output.to_excel(writer, sheet_name='Stationary_Test_Result',index=True)\n",
    "    worksheet_name = os.path.splitext(csv_file)[0]  # Use the input file name as the worksheet name\n",
    "    result.to_excel(writer, sheet_name=worksheet_name, index=True)\n",
    "\n",
    "# Save the Excel file\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
