{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "from util.loggers import createLogHandler\n",
    "from input_handler.data_preprocessor import data_preprocessor\n",
    "from input_handler.load_parameters import load_configuration_file, load_parameters\n",
    "from input_handler.env_setting import run_setting\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from datetime import date\n",
    "from typing import Dict, Optional\n",
    "import pandas as pd\n",
    "from pandas.tseries.offsets import MonthEnd\n",
    "\n",
    "from scipy.stats import norm\n",
    "from typing import Tuple, Dict\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# show all columns and rows of a dataframe\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "configPath = Path(r'C:\\Users\\SA814XM\\Engagement\\03_KhanBank\\kb_ecl_engine\\khb_engine\\run_config_file.json')\n",
    "c = load_configuration_file(configPath=configPath)\n",
    "rc = run_setting(run_config=c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Loading parameter files -------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Loading scenario data -------\n",
      "------- Reading ECL input files -------\n"
     ]
    }
   ],
   "source": [
    "logger = createLogHandler('ecl_calc', rc.logPath/'Log_file_risk_parameter_generation.log')\n",
    "logger.info('********** Initiate ECL Engine Calculator **********')\n",
    "\n",
    "dp = data_preprocessor(context=rc)\n",
    "\n",
    "# Load parameters\n",
    "logger.info('Loading all necessary parameters ...')\n",
    "print('------- Loading parameter files -------') \n",
    "\n",
    "try:\n",
    "        param = load_parameters(parmPath=rc.parmPath)\n",
    "except Exception as e:\n",
    "        logger.exception(\"message\")\n",
    "else:\n",
    "        logger.info('Parameter loading complete.')\n",
    "\n",
    "# load scenario data\n",
    "logger.info('Loading scenario data ...')\n",
    "print('------- Loading scenario data -------') \n",
    "\n",
    "try:\n",
    "        # npl_data_path = Path(\"C:\\\\Users\\\\SA814XM\\\\OneDrive - EY\\\\99_Data_Server\\\\scenario\\\\2024Q2\\\\data\")\n",
    "        npl_data = dp.load_scenario_data(\n",
    "            data_path=rc.dataPathScen, file_pattern='NPL')\n",
    "except Exception as e:\n",
    "        logger.exception(\"message\")\n",
    "else:\n",
    "        logger.info('Scenario data loading complete.')\n",
    "\n",
    "\n",
    "# Load input data\n",
    "logger.info('Reading ECL input files ...')\n",
    "print('------- Reading ECL input files -------') \n",
    "\n",
    "try:\n",
    "        instr_df, _, _ = dp.load_input_data(param=param)\n",
    "\n",
    "        _, _, sa_df, _, _ = dp.run(instr_df=instr_df,\n",
    "                                   run_scope=rc.run_scope,\n",
    "                                   param=param)\n",
    "        \n",
    "        fs_df, is_error = dp.standardize_data(param_dict=param,\n",
    "                                      inDataPath=rc.inDataPath,\n",
    "                                      rawDataName=rc.sa_fs_table_name,\n",
    "                                      inputDataExt=rc.inputDataExtECL,\n",
    "                                      dtype_tbl=rc.dtype_tbl,\n",
    "                                      )\n",
    "\n",
    "        other_df, is_error = dp.standardize_data(param_dict=param,\n",
    "                                        inDataPath=rc.inDataPath,\n",
    "                                        rawDataName=rc.sa_other_debt_table_name,\n",
    "                                        inputDataExt=rc.inputDataExtECL,\n",
    "                                        dtype_tbl=rc.dtype_tbl,\n",
    "                                        )\n",
    "\n",
    "        repay_df, is_error = dp.standardize_data(param_dict=param,\n",
    "                                                inDataPath=rc.inDataPath,\n",
    "                                                rawDataName=rc.repayment_table_name,\n",
    "                                                inputDataExt=rc.inputDataExtECL,\n",
    "                                                dtype_tbl=rc.dtype_tbl)\n",
    "        \n",
    "except Exception as e:\n",
    "        logger.exception(\"message\")\n",
    "else:\n",
    "        logger.info('Input data read successful.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get param dfs\n",
    "es_df = param['Economic_sector']\n",
    "pwa_df = param['pwa']\n",
    "period = param['CFL_LGD_period'].Period.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get class parmas\n",
    "base_year = rc.prev_yymm\n",
    "scenario_version = rc.SCENARIO_VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get in-scope cust list\n",
    "custs = fs_df['CUST_ID'].unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cash flow projection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SA params - output to UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adjustment_factor(df, other_df, cust):\n",
    "    # Get adjustment factor = bal in sa_table / (bal in other_debt + bal in sa_table)\n",
    "    other_df_bal = other_df[other_df['CUST_ID'] == cust].TOTAL_DRAWN_BAL_LCY.sum()\n",
    "    sa_df_bal = df[df['CUST_ID'] == cust].DRAWN_BAL_LCY.sum()\n",
    "    adj_factor = sa_df_bal / (sa_df_bal + other_df_bal)\n",
    "    \n",
    "    return adj_factor\n",
    "\n",
    "\n",
    "def generate_fy_keys(base_year: int, lookback: int = 2, lookforward: int = 3) -> dict:\n",
    "    \"\"\"Generate financial year keys with clear temporal relationships.\"\"\"\n",
    "    fy_dict = {}\n",
    "    \n",
    "    # Previous years\n",
    "    for i in range(1, lookback + 1):\n",
    "        fy_dict[f'prev_{i}'] = date(base_year - i, 12, 31)\n",
    "    \n",
    "    # Current year\n",
    "    fy_dict['curr'] = date(base_year, 12, 31)\n",
    "    \n",
    "    # Future years\n",
    "    for i in range(1, lookforward + 1):\n",
    "        fy_dict[f'next_{i}'] = date(base_year + i, 12, 31)\n",
    "    \n",
    "    return fy_dict\n",
    "\n",
    "\n",
    "def prepare_financial_data(fs_df, cust):\n",
    "    \"\"\"\n",
    "    Prepare financial data by cleaning ITEM_NAME, ensuring STATEMENT_DATE is in date format,\n",
    "    and separating the DataFrame into working capital items (wc_df) and cash-related items (cash_df).\n",
    "\n",
    "    Parameters:\n",
    "        fs_df (pd.DataFrame): The financial statement DataFrame containing columns 'ITEM_NAME', 'STATEMENT_TYPE', and 'STATEMENT_DATE'.\n",
    "\n",
    "    Returns:\n",
    "        wc_df (pd.DataFrame): DataFrame containing working capital items from the balance sheet.\n",
    "        cash_df (pd.DataFrame): DataFrame containing cash-related items from the income statement.\n",
    "    \"\"\"\n",
    "    # TODO: incorporate the ITEM_NAME check in pre_run_validation\n",
    "    fs_df_ = fs_df[fs_df['CUST_ID']==cust].copy()\n",
    "    \n",
    "    # Clean up ITEM_NAME by stripping spaces and replacing them with underscores\n",
    "    fs_df_['ITEM_NAME'] = fs_df_['ITEM_NAME'].str.strip().str.replace(' ', '_')\n",
    "    \n",
    "    # Ensure STATEMENT_DATE is in date format (not datetime)\n",
    "    fs_df_['STATEMENT_DATE'] = pd.to_datetime(fs_df_['STATEMENT_DATE']).dt.date\n",
    "    \n",
    "    # Get unique ITEM_NAME lists for BS (Balance Sheet) and IS (Income Statement)\n",
    "    wc_list = fs_df_[fs_df_['STATEMENT_TYPE'] == 'BS']['ITEM_NAME'].unique().tolist()\n",
    "    cash_list = fs_df_[fs_df_['STATEMENT_TYPE'] == 'IS']['ITEM_NAME'].unique().tolist()\n",
    "    \n",
    "    # Pivot the table to reshape it\n",
    "    fs_df_1 = fs_df_.pivot_table(\n",
    "        index=['ITEM_NAME'], \n",
    "        columns='STATEMENT_DATE', \n",
    "        values='ITEM_AMOUNT', \n",
    "        aggfunc='sum'\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Separate into working capital DataFrame (wc_df)\n",
    "    wc_df = fs_df_1[fs_df_1['ITEM_NAME'].isin(wc_list)]\n",
    "    \n",
    "    # Separate into cash-related DataFrame (cash_df)\n",
    "    cash_df = fs_df_1[fs_df_1['ITEM_NAME'].isin(cash_list)]\n",
    "    \n",
    "    return wc_df, cash_df\n",
    "\n",
    "\n",
    "def get_cash_profit(cash_df, fy_dict):\n",
    "    \"\"\"Calculate cash-based net profit using rolling window averages and clear temporal references.\"\"\"\n",
    "    # Calculate rolling averages using explicit temporal labels\n",
    "    cash_df[fy_dict['next_1']] = cash_df[[fy_dict['prev_2'], fy_dict['prev_1'], fy_dict['curr']]].mean(axis=1)\n",
    "    cash_df[fy_dict['next_2']] = cash_df[[fy_dict['prev_1'], fy_dict['curr'], fy_dict['next_1']]].mean(axis=1)\n",
    "    cash_df[fy_dict['next_3']] = cash_df[[fy_dict['curr'], fy_dict['next_1'], fy_dict['next_2']]].mean(axis=1)\n",
    "    \n",
    "    # Initialize results dataframe with clear structure\n",
    "    cash_profit_df = pd.DataFrame({\n",
    "        'ITEM_NAME': ['Net_profit', 'Depreciation']\n",
    "    })\n",
    "    \n",
    "    # Unified calculation for each forecast year\n",
    "    for year_offset in (1, 2, 3):\n",
    "        year_key = f'next_{year_offset}'\n",
    "        \n",
    "        # Explicit column reference for readability\n",
    "        data = {\n",
    "            'Sales': cash_df.loc[cash_df['ITEM_NAME'] == 'Sales', fy_dict[year_key]].values[0],\n",
    "            'COGS': cash_df.loc[cash_df['ITEM_NAME'] == 'COGS', fy_dict[year_key]].values[0],\n",
    "            'Operating_expense': cash_df.loc[cash_df['ITEM_NAME'] == 'Operating_expense', fy_dict[year_key]].values[0],\n",
    "            'Depreciation_expense': cash_df.loc[cash_df['ITEM_NAME'] == 'Depreciation_expense', fy_dict[year_key]].values[0],\n",
    "            'Other_income': cash_df.loc[cash_df['ITEM_NAME'] == 'Other_income', fy_dict[year_key]].values[0],\n",
    "            'Other_expense': cash_df.loc[cash_df['ITEM_NAME'] == 'Other_expense', fy_dict[year_key]].values[0],\n",
    "            'Realized_FX_gain_(loss)': cash_df.loc[cash_df['ITEM_NAME'] == 'Realized_FX_gain_(loss)', fy_dict[year_key]].values[0],\n",
    "            'Interest_expense': cash_df.loc[cash_df['ITEM_NAME'] == 'Interest_expense', fy_dict[year_key]].values[0],\n",
    "            'Taxes': cash_df.loc[cash_df['ITEM_NAME'] == 'Taxes', fy_dict[year_key]].values[0]\n",
    "        }\n",
    "        \n",
    "        # Clear financial calculations\n",
    "        ebit = (\n",
    "            data['Sales'] \n",
    "            - data['COGS'] \n",
    "            - data['Operating_expense'] \n",
    "            - data['Depreciation_expense'] \n",
    "            + data['Other_income'] \n",
    "            - data['Other_expense'] \n",
    "            + data['Realized_FX_gain_(loss)']\n",
    "        )\n",
    "        \n",
    "        net_profit = ebit - data['Interest_expense'] - data['Taxes']\n",
    "        \n",
    "        # Structured assignment\n",
    "        cash_profit_df.loc[\n",
    "            cash_profit_df['ITEM_NAME'] == 'Net_profit', \n",
    "            fy_dict[year_key]\n",
    "        ] = net_profit\n",
    "        \n",
    "        cash_profit_df.loc[\n",
    "            cash_profit_df['ITEM_NAME'] == 'Depreciation', \n",
    "            fy_dict[year_key]\n",
    "        ] = data['Depreciation_expense']\n",
    "    \n",
    "    return cash_profit_df\n",
    "\n",
    "\n",
    "def get_growth_rate(df, numerator_col, denominator_col):\n",
    "    \"\"\"\n",
    "    Helper function of get_changes_in_working_capital\n",
    "    Calculate growth rate with robust error handling\n",
    "    \"\"\"\n",
    "    result = df[numerator_col] / df[denominator_col] - 1\n",
    "    return result.replace([np.inf, -np.inf, np.nan], 0)\n",
    "\n",
    "\n",
    "def get_changes_in_working_capital(wc_df: pd.DataFrame, fy_dict: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate projected changes in working capital using historical growth patterns.\n",
    "    Applies negative sign convention for asset increases.\n",
    "    \n",
    "    Parameters:\n",
    "        wc_df (pd.DataFrame): Working capital dataframe containing historical values\n",
    "        fy_dict (dict): Fiscal year mapping with temporal keys ('prev_*', 'curr', 'next_*')\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Contains projected working capital changes for future periods\n",
    "    \"\"\"\n",
    "    \n",
    "    # List of asset items requiring negative sign convention\n",
    "    ASSET_ITEMS = [\n",
    "        'Accounts/trade_receivables',\n",
    "        'Other_receivables',\n",
    "        'Intercompany_receivables',\n",
    "        'Inventory',\n",
    "        'Advance_to_suppliers',\n",
    "        'Other_short_term_assets'\n",
    "    ]\n",
    "\n",
    "    df = wc_df.copy()\n",
    "\n",
    "    # 1. Calculate historical growth rates\n",
    "    df['gr_prev_1'] = get_growth_rate(df, fy_dict['prev_1'], fy_dict['prev_2'])\n",
    "    df['gr_curr'] = get_growth_rate(df, fy_dict['curr'], fy_dict['prev_1'])\n",
    "\n",
    "    # 2. Project growth rates\n",
    "    df['gr_next_1'] = df[['gr_prev_1', 'gr_curr']].mean(axis=1)\n",
    "    df['gr_next_2'] = df[['gr_curr', 'gr_next_1']].mean(axis=1)\n",
    "    df['gr_next_3'] = df[['gr_next_1', 'gr_next_2']].mean(axis=1)\n",
    "\n",
    "    # 3. Calculate projected balances\n",
    "    df['tmp_1'] = df[fy_dict['curr']] * (1 + df['gr_next_1'])\n",
    "    df['tmp_2'] = df['tmp_1'] * (1 + df['gr_next_2'])\n",
    "    df['tmp_3'] = df['tmp_2'] * (1 + df['gr_next_3'])\n",
    "\n",
    "    # 4. Calculate changes\n",
    "    df[fy_dict['next_1']] = df['tmp_1'] - df[fy_dict['curr']]\n",
    "    df[fy_dict['next_2']] = df['tmp_2'] - df['tmp_1']\n",
    "    df[fy_dict['next_3']] = df['tmp_3'] - df['tmp_2']\n",
    "\n",
    "    # 5. Apply negative sign convention for assets\n",
    "    asset_mask = df['ITEM_NAME'].isin(ASSET_ITEMS)\n",
    "    for year in ['next_1', 'next_2', 'next_3']:\n",
    "        df.loc[asset_mask, fy_dict[year]] *= -1\n",
    "\n",
    "    return df[['ITEM_NAME', fy_dict['next_1'], fy_dict['next_2'], fy_dict['next_3']]]\n",
    "\n",
    "\n",
    "def get_sa_params_df(cash_profit_df: pd.DataFrame, ciwc_df: pd.DataFrame, fy_dict: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate strategic analysis parameters for cash flow and working capital changes.\n",
    "    \n",
    "    Parameters:\n",
    "        cash_profit_df (pd.DataFrame): DataFrame containing Net_profit and Depreciation\n",
    "        ciwc_df (pd.DataFrame): DataFrame with working capital changes\n",
    "        fy_dict (dict): Fiscal year mapping with 'next_1', 'next_2', 'next_3' keys\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Parameters DataFrame with cash and ciwc values for each forecast period\n",
    "    \"\"\"\n",
    "    \n",
    "    # Validate fiscal year keys\n",
    "    required_keys = ['next_1', 'next_2', 'next_3']\n",
    "    if not all(k in fy_dict for k in required_keys):\n",
    "        missing = [k for k in required_keys if k not in fy_dict]\n",
    "        raise ValueError(f\"Missing fiscal year keys: {missing}\")\n",
    "\n",
    "    # Component definitions\n",
    "    WC_COMPONENTS = {\n",
    "        'negative': [\n",
    "            'Accounts/trade_receivables',\n",
    "            'Intercompany_receivables',\n",
    "            'Other_receivables',\n",
    "            'Inventory',\n",
    "            'Advance_to_suppliers',\n",
    "            'Other_short_term_assets'\n",
    "        ],\n",
    "        'positive': [\n",
    "            'Accounts_payables',\n",
    "            'Intercompany_payables',\n",
    "            'Tax_payable',\n",
    "            'Advances_from_customer',\n",
    "            'Other_current_liabilities'\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # 1. Calculate cash parameters (Net Profit + Depreciation)\n",
    "    cash_values = []\n",
    "    for year_key in required_keys:\n",
    "        year_col = fy_dict[year_key]\n",
    "        try:\n",
    "            np = cash_profit_df.loc[cash_profit_df['ITEM_NAME'] == 'Net_profit', year_col].values[0]\n",
    "            dp = cash_profit_df.loc[cash_profit_df['ITEM_NAME'] == 'Depreciation', year_col].values[0]\n",
    "            cash_values.append(np + dp)\n",
    "        except IndexError:\n",
    "            raise ValueError(f\"Missing Net_profit or Depreciation in {year_key}\")\n",
    "\n",
    "    # 2. Calculate working capital changes\n",
    "    ciwc_values = []\n",
    "    for year_key in required_keys:\n",
    "        year_col = fy_dict[year_key]\n",
    "        try:\n",
    "            negative = ciwc_df.loc[ciwc_df['ITEM_NAME'].isin(WC_COMPONENTS['negative']), year_col].sum()\n",
    "            positive = ciwc_df.loc[ciwc_df['ITEM_NAME'].isin(WC_COMPONENTS['positive']), year_col].sum()\n",
    "            ciwc_values.append(positive + negative)\n",
    "        except KeyError:\n",
    "            raise ValueError(f\"Missing working capital components in {year_col}\")\n",
    "\n",
    "    # 3. Construct final DataFrame\n",
    "    return pd.DataFrame({\n",
    "        'Parameter': ['cash', 'ciwc'],\n",
    "        fy_dict['next_1']: [cash_values[0], ciwc_values[0]],\n",
    "        fy_dict['next_2']: [cash_values[1], ciwc_values[1]],\n",
    "        fy_dict['next_3']: [cash_values[2], ciwc_values[2]]\n",
    "    })\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Cust_ID",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Parameter",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "2024-12-31",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "2025-12-31",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "2026-12-31",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "cc9222d4-21ec-45ff-9730-36b281793b33",
       "rows": [
        [
         "0",
         "DNINULZAV",
         "cash",
         "32913860999.999985",
         "44233814666.6667",
         "43020752888.888954"
        ],
        [
         "1",
         "DNINULZAV",
         "ciwc",
         "-30979987112.507538",
         "-299240502181.6121",
         "-1016466545137.2474"
        ],
        [
         "2",
         "DNWGQVRAQ",
         "cash",
         "255866666.66666657",
         "344488888.8888888",
         "441018518.51851815"
        ],
        [
         "3",
         "DNWGQVRAQ",
         "ciwc",
         "-1015363483.0630536",
         "-1598200878.6354716",
         "-2053787741.8180752"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cust_ID</th>\n",
       "      <th>Parameter</th>\n",
       "      <th>2024-12-31</th>\n",
       "      <th>2025-12-31</th>\n",
       "      <th>2026-12-31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNINULZAV</td>\n",
       "      <td>cash</td>\n",
       "      <td>3.291386e+10</td>\n",
       "      <td>4.423381e+10</td>\n",
       "      <td>4.302075e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DNINULZAV</td>\n",
       "      <td>ciwc</td>\n",
       "      <td>-3.097999e+10</td>\n",
       "      <td>-2.992405e+11</td>\n",
       "      <td>-1.016467e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DNWGQVRAQ</td>\n",
       "      <td>cash</td>\n",
       "      <td>2.558667e+08</td>\n",
       "      <td>3.444889e+08</td>\n",
       "      <td>4.410185e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DNWGQVRAQ</td>\n",
       "      <td>ciwc</td>\n",
       "      <td>-1.015363e+09</td>\n",
       "      <td>-1.598201e+09</td>\n",
       "      <td>-2.053788e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cust_ID Parameter    2024-12-31    2025-12-31    2026-12-31\n",
       "0  DNINULZAV      cash  3.291386e+10  4.423381e+10  4.302075e+10\n",
       "1  DNINULZAV      ciwc -3.097999e+10 -2.992405e+11 -1.016467e+12\n",
       "2  DNWGQVRAQ      cash  2.558667e+08  3.444889e+08  4.410185e+08\n",
       "3  DNWGQVRAQ      ciwc -1.015363e+09 -1.598201e+09 -2.053788e+09"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######## SA CFL LGD Params generation ########\n",
    "\n",
    "fy_dict = generate_fy_keys(int(str(rc.prev_yymm)[:4]))\n",
    "\n",
    "sa_params_list = []\n",
    "\n",
    "# TODO the starting point of the for loop: for cust in custs:\n",
    "for cust in custs:\n",
    "    \n",
    "    sa_df_cust = sa_df[sa_df['CUST_ID'] == cust].copy()\n",
    "    \n",
    "    adj_factor = get_adjustment_factor(sa_df_cust, other_df, cust)\n",
    "    \n",
    "    wc_df, cash_df = prepare_financial_data(fs_df, cust)\n",
    "\n",
    "    cash_profit_df = get_cash_profit(cash_df, fy_dict)\n",
    "    \n",
    "    ciwc_df = get_changes_in_working_capital(wc_df, fy_dict)\n",
    "    \n",
    "    cust_params_df = get_sa_params_df(cash_profit_df, ciwc_df, fy_dict)\n",
    "\n",
    "    # Insert the \"Cust_id\" column as the first column and fill it with \"123\"\n",
    "    cust_params_df.insert(0, \"Cust_ID\", cust)\n",
    "    \n",
    "    sa_params_list.append(cust_params_df)\n",
    "    \n",
    "sa_params_df = pd.concat(sa_params_list, ignore_index=True)\n",
    "sa_params_df = sa_params_df.reset_index(drop=True)\n",
    "\n",
    "sa_params_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cash flow projection (cont.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adjusted SA params -> intput -> get net operating cashflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_net_operating_cashflow(sa_params_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Aggregates all parameter rows into a 'noc' (Net Operating Cash) row\n",
    "    \n",
    "    Parameters:\n",
    "        sa_params_df: DataFrame with columns ['Parameter', 'next_1', 'next_2', 'next_3']\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with original rows plus new 'noc' row containing column sums\n",
    "        \n",
    "    Example Input:\n",
    "        | Parameter | next_1 | next_2 | next_3 |\n",
    "        |-----------|--------|--------|--------|\n",
    "        | cash      | 150    | 165    | 182    |\n",
    "        | ciwc      | -50    | -55    | -60    |\n",
    "        \n",
    "    Example Output:\n",
    "        | Parameter | next_1 | next_2 | next_3 |\n",
    "        |-----------|--------|--------|--------|\n",
    "\n",
    "        | noc       | 100    | 110    | 122    |\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid modifying original data\n",
    "    df = sa_params_df.copy()\n",
    "    \n",
    "    # Calculate sums for each forecast period\n",
    "    noc_values = {\n",
    "        'Parameter': 'noc',\n",
    "        fy_dict['next_1']: df[fy_dict['next_1']].sum(),\n",
    "        fy_dict['next_2']: df[fy_dict['next_2']].sum(),\n",
    "        fy_dict['next_3']: df[fy_dict['next_3']].sum()\n",
    "    }\n",
    "    \n",
    "    # Append new row using concat for pandas>=1.4.0 compatibility\n",
    "    noc_row = pd.DataFrame([noc_values])\n",
    "    return noc_row\n",
    "\n",
    "\n",
    "def _calculate_npl_stats(data: pd.Series, alpha: float) -> Tuple[float, float, float]:\n",
    "    \"\"\"Helper function to calculate NPL statistics\"\"\"\n",
    "    n = len(data)\n",
    "    mean = data.mean()\n",
    "    std = data.std()\n",
    "    \n",
    "    z_score = norm.ppf(1 - alpha/2)\n",
    "    std_err = std / (n ** 0.5)\n",
    "\n",
    "    return (\n",
    "        mean,\n",
    "        mean - z_score * std_err,\n",
    "        mean + z_score * std_err\n",
    "    )\n",
    "\n",
    "\n",
    "def calculate_sector_npl_stats(\n",
    "    es_df: pd.DataFrame,\n",
    "    npl_data: pd.DataFrame,\n",
    "    alpha: float = 0.1\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate NPL statistics with confidence intervals for economic sectors.\n",
    "    \n",
    "    Args:\n",
    "        es_df: DataFrame containing economic sector information with 'ECON_SECTOR_TYPE' column\n",
    "        npl_data: DataFrame containing NPL data with columns named 'SECTOR_NPL_{sector}'\n",
    "        alpha: Significance level for confidence intervals (default: 0.1)\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with columns ['sector', 'mean', 'ci_lower', 'ci_upper']\n",
    "    \"\"\"\n",
    "    # Validate inputs\n",
    "    if 'ECON_SECTOR_TYPE' not in es_df:\n",
    "        raise ValueError(\"es_df must contain 'ECON_SECTOR_TYPE' column\")\n",
    "    \n",
    "    if not 0 < alpha < 1:\n",
    "        raise ValueError(\"Alpha must be between 0 and 1\")\n",
    "\n",
    "    # Generate sector names\n",
    "    sectors = es_df['ECON_SECTOR_TYPE'].unique().tolist()\n",
    "    npl_columns = [f'SECTOR_NPL_{sec}' for sec in sectors]\n",
    "    \n",
    "    # Verify all required columns exist in npl_data\n",
    "    missing_cols = [col for col in npl_columns if col not in npl_data]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Missing NPL columns in npl_data: {missing_cols}\")\n",
    "\n",
    "    # Calculate statistics for each sector\n",
    "    stats = []\n",
    "    for sector, col in zip(sectors, npl_columns):\n",
    "        data = npl_data[col].dropna()\n",
    "        if len(data) < 2:\n",
    "            raise ValueError(f\"Insufficient data for sector {sector}\")\n",
    "            \n",
    "        mean, ci_lower, ci_upper = _calculate_npl_stats(data, alpha)\n",
    "        stats.append({\n",
    "            'npl_sector': sector,\n",
    "            'mean': mean,\n",
    "            'ci_lower': ci_lower,\n",
    "            'ci_upper': ci_upper\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(stats)\n",
    "\n",
    "\n",
    "def get_total_repay_df(df, repay_df):\n",
    "    contract_ids = df.CONTRACT_ID.unique().tolist()\n",
    "    cust_repay = repay_df[repay_df['CONTRACT_ID'].isin(contract_ids)]\n",
    "    \n",
    "    ttl_repay = cust_repay.pivot_table(index='CF_DATE', columns='CONTRACT_ID', values='PRIN_PMT_OCY')\n",
    "    ttl_repay['ttl_repay'] = ttl_repay.sum(axis=1)\n",
    "    \n",
    "    return ttl_repay[['ttl_repay']]\n",
    "\n",
    "\n",
    "def get_cash_flow_dates(scenario_date: str, period_years: int) -> pd.DatetimeIndex:\n",
    "    \"\"\"\n",
    "    Generate monthly cash flow dates starting from the quarter following the scenario date.\n",
    "    \n",
    "    Args:\n",
    "        scenario_date: Format 'YYYYQX' where X is quarter (1-4)\n",
    "        period_years: Number of years to project forward\n",
    "        \n",
    "    Returns:\n",
    "        Monthly DatetimeIndex through end of projection period\n",
    "        \n",
    "    Example:\n",
    "        >>> get_cash_flow_dates('2023Q4', 5)\n",
    "        DatetimeIndex(['2024-01-31', '2024-02-29', ..., '2027-12-31'], dtype='datetime64[ns]', freq='M')\n",
    "    \"\"\"\n",
    "    # Validate input format\n",
    "    if len(scenario_date) != 6 or not scenario_date[4] == 'Q':\n",
    "        raise ValueError(\"Scenario date must be in format 'YYYYQX' (e.g. '2023Q4')\")\n",
    "    \n",
    "    year = int(scenario_date[:4])\n",
    "    quarter = int(scenario_date[-1])\n",
    "    \n",
    "    if not 1 <= quarter <= 4:\n",
    "        raise ValueError(\"Quarter must be between 1-4\")\n",
    "\n",
    "    # Calculate start date\n",
    "    if quarter == 4:\n",
    "        start_year = year + 1\n",
    "        start_month = 1\n",
    "    else:\n",
    "        start_year = year\n",
    "        start_month = quarter * 3 + 1  # Next quarter start month\n",
    "        \n",
    "    start_date = pd.Timestamp(year=start_year, month=start_month, day=1) + MonthEnd(1)\n",
    "    \n",
    "    # Calculate end date\n",
    "    end_date = pd.Timestamp(year + period_years - 1, 12, 31)\n",
    "    \n",
    "    return pd.date_range(start=start_date, end=end_date, freq='M')\n",
    "\n",
    "\n",
    "def get_pwa_noc(\n",
    "    fy_dict: Dict[str, int],\n",
    "    sa_df_cust: pd.DataFrame,\n",
    "    noc_df: pd.DataFrame,\n",
    "    npl_stats: pd.DataFrame,\n",
    "    pwa_df: pd.DataFrame,\n",
    "    cust: str\n",
    ") -> Optional[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Calculate Probability-Weighted Average Net Operating Cash (NOC) for a customer.\n",
    "    \n",
    "    Args:\n",
    "        fy_dict: Fiscal year mapping {'next_1': 2024, ...}\n",
    "        sa_df_cust: Strategic analysis dataframe with customer-sector mapping\n",
    "        noc_df: NOC projections dataframe\n",
    "        npl_stats: Sector NPL statistics with confidence intervals\n",
    "        pwa_df: Scenario probability weights\n",
    "        cust_id: Target customer ID\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with PWA NOC projections or None if invalid input\n",
    "    \"\"\"\n",
    "        \n",
    "    sectors = sa_df_cust['ECON_SECTOR'].unique()\n",
    "    if len(sectors) > 1:\n",
    "        print(f\"Customer {cust} has multiple sectors: {sectors}\")\n",
    "        return None\n",
    "    \n",
    "    # print(sectors[0])\n",
    "    sector_type = es_df.loc[es_df['ECON_SECTOR'] == sectors[0], 'ECON_SECTOR_TYPE'].iloc[0]\n",
    "    \n",
    "    # Get NPL risk factor\n",
    "    try:\n",
    "        sector_stats = npl_stats.query(f\"npl_sector == '{sector_type}'\").iloc[0]\n",
    "        risk_factor = (sector_stats['mean'] - sector_stats['ci_lower']) / sector_stats['mean']\n",
    "\n",
    "    except IndexError:\n",
    "        print(f\"No NPL stats found for sector {sector_type}\")\n",
    "        return None\n",
    "\n",
    "    # Calculate scenario-adjusted NOC\n",
    "    results = []\n",
    "    for year_key in ['next_1', 'next_2', 'next_3']:\n",
    "        if year_key not in fy_dict:\n",
    "            print(f\"Missing fiscal year key {year_key}\")\n",
    "            return None\n",
    "            \n",
    "        fiscal_year = fy_dict[year_key]\n",
    "        base_noc = noc_df.get(fiscal_year, 0)\n",
    "        \n",
    "        # Scenario adjustments\n",
    "        scenarios = {\n",
    "            'SEVE': base_noc * (1 - risk_factor),\n",
    "            'BASE': base_noc,\n",
    "            'GROW': base_noc * (1 + risk_factor)\n",
    "        }\n",
    "        \n",
    "        # Apply probability weights\n",
    "        pwa_noc = sum(\n",
    "            scenarios[scenario] * pwa_df.loc[pwa_df['scenario'] == scenario, 'pwa'].values[0]\n",
    "            for scenario in ['SEVE', 'BASE', 'GROW']\n",
    "        )\n",
    "\n",
    "        results.append({'prediction_year': fiscal_year, 'pwa_noc': pwa_noc.iloc[0]\n",
    "})\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "def get_total_exposure(df):\n",
    "    return df['PRIN_BAL_LCY'].sum() + df['ACRU_INT_LCY'].sum()\n",
    "\n",
    "\n",
    "def get_cust_EIR(df):\n",
    "    eir = df['EFF_INT_RT']\n",
    "    exposure = df['PRIN_BAL_LCY'] + df['ACRU_INT_LCY']\n",
    "\n",
    "    return (eir * exposure).sum() / exposure.sum()\n",
    "\n",
    "\n",
    "def get_lgd_df(cash_flow_dates: pd.DatetimeIndex, pwa_noc_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create Loss Given Date (LGD) DataFrame with datetime index preservation.\n",
    "    \n",
    "    Args:\n",
    "        cash_flow_dates: Monthly cash flow dates (DatetimeIndex)\n",
    "        pwa_noc_df: Annual NOC projections with prediction years\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with cash flow dates as index and total NOC values\n",
    "    \"\"\"\n",
    "    # Convert prediction years to datetime and extract year\n",
    "    annual_noc = pwa_noc_df.copy()\n",
    "    annual_noc['year'] = pd.to_datetime(annual_noc['prediction_year']).dt.year\n",
    "\n",
    "    # Create base dataframe with cash flow dates as index\n",
    "    lgd_df = pd.DataFrame(index=cash_flow_dates)\n",
    "    lgd_df.index.name = 'cash_flow_date'\n",
    "    \n",
    "    # Extract year from index and prepare for merge\n",
    "    lgd_df = lgd_df.assign(year=lgd_df.index.year).reset_index()\n",
    "    \n",
    "    # Merge with annual NOC values\n",
    "    lgd_df = lgd_df.merge(\n",
    "        annual_noc[['year', 'pwa_noc']],\n",
    "        on='year',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Restore datetime index and clean up\n",
    "    lgd_df = lgd_df.set_index('cash_flow_date').sort_index()\n",
    "    lgd_df = lgd_df[['pwa_noc']].rename(columns={'pwa_noc': 'ttl_noc'})\n",
    "    \n",
    "    # Forward fill within each year group and fill remaining NAs\n",
    "    lgd_df['ttl_noc'] = lgd_df['ttl_noc'].ffill().fillna(0)\n",
    "    \n",
    "    return lgd_df\n",
    "\n",
    "\n",
    "def add_discounted_col(\n",
    "    df: pd.DataFrame,\n",
    "    lgd_df: pd.DataFrame,\n",
    "    col: str,\n",
    "    eir: float\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Add discounted NOC column using time-aware discounting.\n",
    "    \n",
    "    Args:\n",
    "        lgd_df: DataFrame with cash_flow_date index and ttl_noc column\n",
    "        reporting_date: Base date for discounting (e.g. '2024-06-30')\n",
    "        eir: Effective interest rate (e.g. 0.05 for 5%)\n",
    "        \n",
    "    Returns:\n",
    "        Modified DataFrame with discounted_noc column\n",
    "    \"\"\"\n",
    "    # Convert reporting date to pandas timestamp if not already\n",
    "    # TODO: chk if the report_date of one cust is unique and = the scenario date\n",
    "    reporting_date = df['REPORT_DATE'].unique()[0]\n",
    "    \n",
    "    # Calculate time delta in years\n",
    "    delta_days = (lgd_df.index - reporting_date).days\n",
    "    delta_years = delta_days / 365\n",
    "    \n",
    "    # Calculate discount factor\n",
    "    discount_factor = (1 + eir) ** delta_years\n",
    "    \n",
    "    # Calculate discounted NOC\n",
    "    lgd_df[f'discounted_{col}'] = lgd_df[col] / discount_factor\n",
    "    \n",
    "    return lgd_df\n",
    "\n",
    "\n",
    "def get_total_recovery(lgd_df_1):\n",
    "    \"\"\"\n",
    "    Calculate the total recoverable amount (delayed repayment plan version)\n",
    "    New logic: If the cash flow is insufficient in a given month, the entire repayment plan is shifted back by one month until the cumulative cash flow is sufficient to cover the repayment.\n",
    "    \"\"\"\n",
    "    total_recovery = 0.0\n",
    "    carry_over = 0.0      # Cumulative available cash flow\n",
    "    pending_repayments = []  # Queue for pending repayment plans\n",
    "    \n",
    "    # Process data in chronological order\n",
    "    df = lgd_df_1.sort_index()\n",
    "    \n",
    "    for date, row in df.iterrows():\n",
    "        discounted_noc = row[\"discounted_ttl_noc\"]\n",
    "        ttl_repay = row[\"discounted_ttl_repay\"]\n",
    "        \n",
    "        # Add the current month's repayment plan to the queue\n",
    "        pending_repayments.append(ttl_repay)\n",
    "        \n",
    "        # Handle negative cash flow\n",
    "        current_noc = max(discounted_noc, 0.0)\n",
    "        carry_over += current_noc  # Accumulate cash flow\n",
    "        \n",
    "        # Attempt to process the first repayment plan in the queue\n",
    "        while len(pending_repayments) > 0 and carry_over >= pending_repayments[0]:\n",
    "            # Repay the earliest outstanding debt\n",
    "            repaid = pending_repayments.pop(0)\n",
    "            total_recovery += repaid\n",
    "            carry_over -= repaid\n",
    "    \n",
    "    return total_recovery\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNINULZAV 0.5421736916332003\n",
      "DNWGQVRAQ 1.0\n"
     ]
    }
   ],
   "source": [
    "# TODO: update the adj_sa_params_df\n",
    "sa_params_df_adj = sa_params_df.copy()\n",
    "\n",
    "for cust in custs:\n",
    "    sa_df_cust = sa_df[sa_df['CUST_ID'] == cust].copy()\n",
    "    \n",
    "    ### Adjusted SA params -> intput -> get net operating cashflow\n",
    "    cust_df = sa_params_df_adj[sa_params_df_adj['Cust_ID'] == cust].copy()\n",
    "    noc_df = get_net_operating_cashflow(sa_params_df=cust_df)\n",
    "    \n",
    "    ### LGD calculation\n",
    "    \n",
    "    # NPL statistics\n",
    "    npl_stats = calculate_sector_npl_stats(es_df, npl_data, alpha=0.1)\n",
    "\n",
    "    # LGD\n",
    "    ttl_repay_df = get_total_repay_df(sa_df_cust, repay_df)\n",
    "    cash_flow_dates = get_cash_flow_dates(rc.SCENARIO_VERSION, period)\n",
    "    \n",
    "    # TODO: change the noc_df back after the params are decided\n",
    "    noc_df_fake = pd.DataFrame({\n",
    "        'Parameter': ['noc'],\n",
    "        fy_dict['next_1']: [150033428750.2],\n",
    "        fy_dict['next_2']: [13410669664.88],\n",
    "        fy_dict['next_3']: [67990473450.6879]\n",
    "    })\n",
    "\n",
    "    \n",
    "    pwa_noc_df = get_pwa_noc(fy_dict, sa_df_cust, noc_df, npl_stats, pwa_df, cust)\n",
    "    \n",
    "    ttl_exposure = get_total_exposure(sa_df_cust)\n",
    "    \n",
    "    eir = get_cust_EIR(sa_df_cust)\n",
    "\n",
    "    lgd_df = get_lgd_df(cash_flow_dates, pwa_noc_df)\n",
    "\n",
    "    lgd_df_1 = lgd_df.merge(ttl_repay_df, how='left', left_index=True, right_index=True).copy()\n",
    "    lgd_df_1 = lgd_df_1.fillna(0)  # Fill NaN values with 0\n",
    "\n",
    "    \n",
    "    lgd_df_2 = add_discounted_col(\n",
    "        sa_df_cust,\n",
    "        lgd_df_1,\n",
    "        'ttl_noc',\n",
    "        eir=eir\n",
    "    )\n",
    "\n",
    "    lgd_df_2 = add_discounted_col(\n",
    "        sa_df_cust,\n",
    "        lgd_df_1,\n",
    "        'ttl_repay',\n",
    "        eir=eir\n",
    "    )\n",
    "    \n",
    "    ttl_recover = get_total_recovery(lgd_df_1)\n",
    "    lgd = 1 - ttl_recover/ttl_exposure\n",
    "\n",
    "    print(cust, lgd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
